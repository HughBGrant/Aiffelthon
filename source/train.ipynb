{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950ff52c",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7922db8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, time, datetime\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81243264",
   "metadata": {},
   "source": [
    "# 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35894dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_name = \"data/dialogue.csv\"\n",
    "    bos_token = '<s>'\n",
    "    eos_token = '</s>'\n",
    "    usr_token = '<usr>'\n",
    "    pad_token = '<pad>'\n",
    "    sys_token = '<sys>'\n",
    "    unk_token = '<unk>'\n",
    "    mask_token = '<mask>'\n",
    "    max_length = 2 ** 8\n",
    "    batch_size = 2 ** 3\n",
    "    epochs = 2 ** 2\n",
    "    pretrained_model_name = \"skt/kogpt2-base-v2\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 3e-5\n",
    "    model_name = 'model.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf737870",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bf4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(Config.data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f05233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178983</th>\n",
       "      <td>&lt;usr&gt; 결혼식 날에 신부 입장할때 너무 뭉클했어&lt;sys&gt; 나는 결혼식하는 것만 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193936</th>\n",
       "      <td>&lt;usr&gt; 댄스 말고 배워보고 싶은거 있어?&lt;sys&gt; 댄스 말고는 악기 배우고 싶어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118970</th>\n",
       "      <td>&lt;usr&gt; 나 도착했어 &lt;sys&gt; 오 일찍왔네?기장님이 좀 밟으셧나봐ㅋㅋ 짐 찾았어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141438</th>\n",
       "      <td>&lt;usr&gt; 오늘도 축구 예선전이 있다고 하네요&lt;sys&gt; 어디서 중계 하려나요?&lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151905</th>\n",
       "      <td>&lt;usr&gt; 니 자동차 별칭은 따로 안 정했어?&lt;sys&gt; 그냥 한 번씩 흰둥이라고 불...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100692</th>\n",
       "      <td>&lt;usr&gt; 혜경자지말고 식순 정해친구도 연습할시간 주구대본도 짜줘야하니 &lt;sys&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160230</th>\n",
       "      <td>&lt;usr&gt; 너 현금 쓰면 현금 영수증 끊어?&lt;sys&gt; 웅 당연히 끊지 ㅋㅋ아빠 껄로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162693</th>\n",
       "      <td>&lt;usr&gt; 아직도 장애인들이 대중교통을 이용할 때 많이 불편한가 보더라고&lt;sys&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67764</th>\n",
       "      <td>&lt;usr&gt; 점심시간 &lt;sys&gt; 응응 맛난 거 먹장! &lt;usr&gt; 콩국수요 &lt;sys&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59286</th>\n",
       "      <td>&lt;usr&gt; 나 사실 걍 유튜브에 검색하면15분정도 영화설명해주는거그것도 띄엄띄엄 보...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194475 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             conversation\n",
       "178983  <usr> 결혼식 날에 신부 입장할때 너무 뭉클했어<sys> 나는 결혼식하는 것만 ...\n",
       "193936  <usr> 댄스 말고 배워보고 싶은거 있어?<sys> 댄스 말고는 악기 배우고 싶어...\n",
       "118970  <usr> 나 도착했어 <sys> 오 일찍왔네?기장님이 좀 밟으셧나봐ㅋㅋ 짐 찾았어...\n",
       "141438  <usr> 오늘도 축구 예선전이 있다고 하네요<sys> 어디서 중계 하려나요?<us...\n",
       "151905  <usr> 니 자동차 별칭은 따로 안 정했어?<sys> 그냥 한 번씩 흰둥이라고 불...\n",
       "...                                                   ...\n",
       "100692  <usr> 혜경자지말고 식순 정해친구도 연습할시간 주구대본도 짜줘야하니 <sys> ...\n",
       "160230  <usr> 너 현금 쓰면 현금 영수증 끊어?<sys> 웅 당연히 끊지 ㅋㅋ아빠 껄로...\n",
       "162693  <usr> 아직도 장애인들이 대중교통을 이용할 때 많이 불편한가 보더라고<sys> ...\n",
       "67764   <usr> 점심시간 <sys> 응응 맛난 거 먹장! <usr> 콩국수요 <sys> ...\n",
       "59286   <usr> 나 사실 걍 유튜브에 검색하면15분정도 영화설명해주는거그것도 띄엄띄엄 보...\n",
       "\n",
       "[194475 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(raw_data)\n",
    "data = raw_data.sample(N)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d5b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_size(train_X):\n",
    "    length = len(train_X)\n",
    "    return round(0.14 * (1 + length / 10 ** 4) ** (10 ** 4 / length) - 0.13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77e3dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size=valid_size(data), shuffle=True)\n",
    "data_train.reset_index(inplace=True)\n",
    "data_valid.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c837c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191862</td>\n",
       "      <td>&lt;usr&gt; 일남 할아버지 근데 죽잖아&lt;sys&gt; 죽는 장면이 안나와..&lt;usr&gt; 아하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40611</td>\n",
       "      <td>&lt;usr&gt; 오 피우는 비타민이란거있대연기도나고ㅋㅋ &lt;sys&gt; 헐?!진짜?산다 &lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38757</td>\n",
       "      <td>&lt;usr&gt; 저녁으로 먹는거 토마토주스맛나는거 내 안무야겠따 하루종일까스 개쩖 엄마눙...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>136104</td>\n",
       "      <td>&lt;usr&gt; 우리는 다 배가 부르단다 ㅋㅋ뭘 먹었는지 모르게 헛배불러 ㅋㅋ인자 내 씻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117244</td>\n",
       "      <td>&lt;usr&gt; 아글고 아까 저 괴상하게 생긴 굿즈 &lt;sys&gt; 벌써웃겨 &lt;usr&gt; 집에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188635</th>\n",
       "      <td>50657</td>\n",
       "      <td>&lt;usr&gt; 어플로 보면 할인되는거 아이폰은 안나와ㅠㅠ난 몇개월할인받아서 끝나면 해지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188636</th>\n",
       "      <td>191844</td>\n",
       "      <td>&lt;usr&gt; 양평 쪽에도 좋은 집이 많더라&lt;sys&gt; 서울이랑 거리도 가까워서 그런가?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188637</th>\n",
       "      <td>175005</td>\n",
       "      <td>&lt;usr&gt; 부모님께 선물은 어버이날만 사드린다는 고정관념이 생겼어요&lt;sys&gt; 전 생...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188638</th>\n",
       "      <td>7962</td>\n",
       "      <td>&lt;usr&gt; 나 이민규야 달고싶은데진짜 삐질거같아서참을게 &lt;sys&gt; 정미현야 ㅠㅠ시스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188639</th>\n",
       "      <td>16110</td>\n",
       "      <td>&lt;usr&gt; 아씨 내일 엄마가게 일가야되느데망핸 &lt;sys&gt; 왜 &lt;usr&gt; 지금 일어나...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                       conversation\n",
       "0       191862  <usr> 일남 할아버지 근데 죽잖아<sys> 죽는 장면이 안나와..<usr> 아하...\n",
       "1        40611  <usr> 오 피우는 비타민이란거있대연기도나고ㅋㅋ <sys> 헐?!진짜?산다 <us...\n",
       "2        38757  <usr> 저녁으로 먹는거 토마토주스맛나는거 내 안무야겠따 하루종일까스 개쩖 엄마눙...\n",
       "3       136104  <usr> 우리는 다 배가 부르단다 ㅋㅋ뭘 먹었는지 모르게 헛배불러 ㅋㅋ인자 내 씻...\n",
       "4       117244  <usr> 아글고 아까 저 괴상하게 생긴 굿즈 <sys> 벌써웃겨 <usr> 집에 ...\n",
       "...        ...                                                ...\n",
       "188635   50657  <usr> 어플로 보면 할인되는거 아이폰은 안나와ㅠㅠ난 몇개월할인받아서 끝나면 해지...\n",
       "188636  191844  <usr> 양평 쪽에도 좋은 집이 많더라<sys> 서울이랑 거리도 가까워서 그런가?...\n",
       "188637  175005  <usr> 부모님께 선물은 어버이날만 사드린다는 고정관념이 생겼어요<sys> 전 생...\n",
       "188638    7962  <usr> 나 이민규야 달고싶은데진짜 삐질거같아서참을게 <sys> 정미현야 ㅠㅠ시스...\n",
       "188639   16110  <usr> 아씨 내일 엄마가게 일가야되느데망핸 <sys> 왜 <usr> 지금 일어나...\n",
       "\n",
       "[188640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a535ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163158</td>\n",
       "      <td>&lt;usr&gt; 안녕형 나 야식 추천 좀!&lt;sys&gt; 야식은 족발 아니겠어? ㅋㅋ족발 어때...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145555</td>\n",
       "      <td>&lt;usr&gt; 나 네일을 받아볼까?&lt;sys&gt; 네일 받아 보는거 나쁘지 않지&lt;usr&gt; 네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77339</td>\n",
       "      <td>&lt;usr&gt; 핸드폰 테마를바꾸고 싶은뎅추천해종 &lt;sys&gt; 음.. 지금 너가 쓰는건파스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167021</td>\n",
       "      <td>&lt;usr&gt; 너 예전에 별에서 온 그대 드라마 봤어?&lt;sys&gt; 네 저 그거 봤죠 ㅋㅋ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101071</td>\n",
       "      <td>&lt;usr&gt; 아프지않게 주사놓는게어렵지않나 &lt;sys&gt; 레이저할 때 아프지않게주사놪 다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>38533</td>\n",
       "      <td>&lt;usr&gt; 아진짜 &lt;sys&gt; 건강하게 &lt;usr&gt; 건강상할정도로만 &lt;sys&gt; 다먹는거...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>182716</td>\n",
       "      <td>&lt;usr&gt; 아이돌 굿즈 종류도 정말 많더라&lt;sys&gt; 어떤게 인기 있어?&lt;usr&gt; 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>59997</td>\n",
       "      <td>&lt;usr&gt; 개피곤하구만..역학부터채점한다 ㅎ ㅎ &lt;sys&gt; ㅎ..하고말해주라 &lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>56714</td>\n",
       "      <td>&lt;usr&gt; 한자외우는데 너무 외롭다..이건 외로운 싸움이야90개외우고 50개틀린듯ㅠ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>183548</td>\n",
       "      <td>&lt;usr&gt; 좋아하는 아이돌 있어?요즘 아이돌이 너무 많아&lt;sys&gt; 난 요새 오마이걸...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       conversation\n",
       "0     163158  <usr> 안녕형 나 야식 추천 좀!<sys> 야식은 족발 아니겠어? ㅋㅋ족발 어때...\n",
       "1     145555  <usr> 나 네일을 받아볼까?<sys> 네일 받아 보는거 나쁘지 않지<usr> 네...\n",
       "2      77339  <usr> 핸드폰 테마를바꾸고 싶은뎅추천해종 <sys> 음.. 지금 너가 쓰는건파스...\n",
       "3     167021  <usr> 너 예전에 별에서 온 그대 드라마 봤어?<sys> 네 저 그거 봤죠 ㅋㅋ...\n",
       "4     101071  <usr> 아프지않게 주사놓는게어렵지않나 <sys> 레이저할 때 아프지않게주사놪 다...\n",
       "...      ...                                                ...\n",
       "5830   38533  <usr> 아진짜 <sys> 건강하게 <usr> 건강상할정도로만 <sys> 다먹는거...\n",
       "5831  182716  <usr> 아이돌 굿즈 종류도 정말 많더라<sys> 어떤게 인기 있어?<usr> 기...\n",
       "5832   59997  <usr> 개피곤하구만..역학부터채점한다 ㅎ ㅎ <sys> ㅎ..하고말해주라 <us...\n",
       "5833   56714  <usr> 한자외우는데 너무 외롭다..이건 외로운 싸움이야90개외우고 50개틀린듯ㅠ...\n",
       "5834  183548  <usr> 좋아하는 아이돌 있어?요즘 아이돌이 너무 많아<sys> 난 요새 오마이걸...\n",
       "\n",
       "[5835 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c2e73",
   "metadata": {},
   "source": [
    "# 3. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f625447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Config.pretrained_model_name,\n",
    "            bos_token=Config.bos_token, eos_token=Config.eos_token,\n",
    "            unk_token=Config.unk_token, pad_token=Config.pad_token,\n",
    "            mask_token=Config.mask_token, model_max_length=Config.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ac9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <usr> <pad> <sys> <unk> <mask> <d> </d> <unused0> "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tokenizer.convert_ids_to_tokens(i), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f921f02",
   "metadata": {},
   "source": [
    "# 4. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d491b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, Config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.pad_token = Config.pad_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.max_length = Config.max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data['conversation'][idx]\n",
    "        # input_id\n",
    "        input_id = self.tokenizer.encode(self.bos_token + sentence + self.eos_token)\n",
    "        # token_type_id\n",
    "        token_type = []\n",
    "        loop = True\n",
    "        for token_id in input_id:\n",
    "            token = self.tokenizer.convert_ids_to_tokens(token_id)\n",
    "            \n",
    "            if token == self.usr_token: loop=True\n",
    "            elif token == self.sys_token: loop=False\n",
    "                \n",
    "            if loop:\n",
    "                token_type.append(self.usr_token)\n",
    "            else:\n",
    "                token_type.append(self.sys_token)\n",
    "        token_type_id = self.tokenizer.convert_tokens_to_ids(token_type)\n",
    "        # label\n",
    "        start_idx = len(input_id) - \\\n",
    "            list(reversed(input_id)).index(self.tokenizer.convert_tokens_to_ids(self.sys_token))\n",
    "        label = [-100] * start_idx + input_id[start_idx: ]\n",
    "        # padding\n",
    "        input_id, token_type_id, label = self.make_padding(input_id, token_type_id, label)\n",
    "        \n",
    "        return input_id, token_type_id, label\n",
    "\n",
    "    def make_padding(self, input_id, token_type_id, label):\n",
    "        left_length = self.max_length - len(input_id)\n",
    "        input_id += [self.tokenizer.pad_token_id] * left_length\n",
    "        token_type_id += [self.tokenizer.pad_token_id] * left_length\n",
    "        label += [-100] * left_length\n",
    "        \n",
    "        return input_id, token_type_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e15d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(data_train, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b5a5cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 9043, 7062, 32857, 9252, 7220, 9393, 8162, 7965, 4, 24736, 36713, 9183, 16621, 9705, 2, 9050, 8702, 9705, 36550, 9339, 11117, 12964, 406, 4, 9032, 8774, 9760, 9089, 20759, 12312, 7532, 36759, 9390, 12752, 7489, 25571, 2, 20713, 9105, 8146, 8015, 7182, 9407, 7501, 8148, 6855, 15247, 406, 4, 11403, 11525, 44235, 6872, 6853, 7172, 9658, 14902, 13348, 9138, 14990, 11902, 6853, 8263, 9705, 8420, 7501, 20430, 6857, 406, 9252, 7220, 11432, 8220, 8000, 14668, 9022, 6855, 9622, 8137, 6853, 7991, 2, 11403, 9043, 7623, 9021, 23598, 6853, 7991, 406, 10278, 4, 19896, 8018, 9252, 7220, 23971, 9042, 9313, 14909, 9025, 9080, 6853, 8041, 12896, 9705, 8006, 8456, 14927, 9337, 9025, 11218, 9705, 406, 2, 9063, 24107, 9847, 8420, 8015, 7182, 12118, 7545, 7379, 8020, 739, 605, 605, 4, 739, 605, 605, 35704, 9572, 50624, 10056, 7055, 7788, 29144, 7788, 9181, 12306, 6853, 8263, 47318, 10030, 9847, 8420, 9350, 8353, 8137, 6857, 406, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 739, 605, 605, 35704, 9572, 50624, 10056, 7055, 7788, 29144, 7788, 9181, 12306, 6853, 8263, 47318, 10030, 9847, 8420, 9350, 8353, 8137, 6857, 406, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = train_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc5dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [items[0] for items in batch]\n",
    "    token_type_ids = [items[1] for items in batch]\n",
    "    labels = [items[2] for items in batch]\n",
    "    \n",
    "    return torch.LongTensor(input_ids), torch.LongTensor(token_type_ids), \\\n",
    "            torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e802edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                              shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e4546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = CustomDataset(data_valid, tokenizer, Config)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                            shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc20a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 25906, 8745, 9063, 9893, 7889, 13815, 11732, 376, 4, 9893, 11187, 13429, 7601, 9320, 6872, 8006, 406, 739, 605, 605, 8214, 7601, 9105, 7312, 2, 9050, 9077, 7471, 739, 605, 605, 8214, 7601, 22238, 19104, 739, 605, 605, 4, 739, 605, 605, 9050, 13429, 7601, 31187, 6958, 19202, 6972, 12218, 8346, 8214, 7601, 739, 7318, 6960, 7182, 2, 739, 605, 605, 9050, 12218, 8346, 8214, 7601, 9036, 39749, 9183, 33146, 7662, 9668, 11355, 8155, 8139, 406, 4, 10278, 7756, 32951, 10510, 8159, 12011, 9511, 47317, 12011, 8705, 9122, 9239, 7220, 406, 2, 739, 605, 605, 9105, 9063, 10253, 12011, 9328, 6947, 6853, 11355, 18479, 9277, 9293, 11629, 406, 4, 9346, 8148, 8191, 11848, 10464, 9383, 739, 605, 605, 41732, 33146, 7661, 2, 9050, 9022, 6853, 9351, 9293, 15713, 11629, 739, 605, 605, 9114, 8052, 7970, 7415, 8244, 7788, 9065, 7495, 9173, 376, 4, 739, 605, 605, 9054, 16539, 7098, 6853, 6958, 17088, 11355, 49067, 12790, 33146, 7661, 739, 605, 605, 2, 739, 605, 605, 40057, 406, 13429, 7601, 18339, 17088, 35879, 406, 4, 24694, 8187, 9341, 739, 605, 605, 6910, 8338, 7208, 7372, 22507, 13815, 10013, 7513, 8006, 10704, 39020, 8548, 9065, 7495, 9217, 12451, 9124, 10341, 9122, 7991, 9705, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 24694, 8187, 9341, 739, 605, 605, 6910, 8338, 7208, 7372, 22507, 13815, 10013, 7513, 8006, 10704, 39020, 8548, 9065, 7495, 9217, 12451, 9124, 10341, 9122, 7991, 9705, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = valid_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d0b825",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f26a6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(Config.pretrained_model_name).to(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc74561",
   "metadata": {},
   "source": [
    "# 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "457ec313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, model, tokenizer, Config):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=Config.learning_rate)\n",
    "#         self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.9)\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.device = Config.device\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "\n",
    "    def train(self, epochs, train_dataloader, valid_dataloader=None, save=False):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch: {epoch + 1} / {epochs}\")\n",
    "            self.model.train()\n",
    "            losses = []\n",
    "            start_time = time.time()\n",
    "\n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch        \n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                train_loss = np.mean(losses)\n",
    "                print(self.status(i + 1, len(train_dataloader), time.time() - start_time,\n",
    "                                  train_loss), end='\\r')\n",
    "                \n",
    "#             self.scheduler.step()\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            if valid_dataloader:\n",
    "                valid_loss = self.validation(valid_dataloader)\n",
    "                print(self.status(i + 1, len(train_dataloader), time.time() - start_time,\n",
    "                                train_loss) + f\" #valid_loss: {valid_loss:.6f}\\n\", end='\\r')\n",
    "                self.valid_losses.append(valid_loss)\n",
    "            \n",
    "            if save:\n",
    "                time_zone = datetime.timezone(datetime.timedelta(hours=9))\n",
    "                now = datetime.datetime.now(time_zone)\n",
    "                PATH = now.strftime(f'models/%m%d_%H%M_ep{epoch + 1}.pt')\n",
    "                torch.save(self.model.state_dict(), PATH)\n",
    "\n",
    "    def validation(self, valid_dataloader):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(valid_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                losses.append(loss.item())\n",
    "            \n",
    "            valid_loss = np.mean(losses)\n",
    "        \n",
    "        return valid_loss\n",
    "    \n",
    "    def status(self, step, steps, past_time, train_loss):\n",
    "        return f\"#step: {step} / {steps} #past: {int(past_time)}s #left: {int(steps / step * time - time)}s #train_loss: {train_loss:.6f}\"\n",
    "\n",
    "    def save(self, PATH=None):\n",
    "        if not PATH:\n",
    "            time_zone = datetime.timezone(datetime.timedelta(hours=9))\n",
    "            now = datetime.datetime.now(time_zone)\n",
    "            PATH = now.strftime(f'models/%m%d_%H%M_ep{epochs}.pt')\n",
    "            \n",
    "        torch.save(self.model.state_dict(), PATH)\n",
    "        print(\"model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171fa65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chathuman = Train(model, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80208456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 4\n",
      "#step: 23580 / 23580 #past: 13389s #left: 0s #train_loss: 4.269815 #valid_loss: 4.106904\n",
      "Epoch: 2 / 4\n",
      "#step: 23580 / 23580 #past: 13400s #left: 0s #train_loss: 3.899102 #valid_loss: 4.036246\n",
      "Epoch: 3 / 4\n",
      "#step: 6336 / 23580 #past: 3559s #left: 9688s #train_loss: 3.5654347\r"
     ]
    }
   ],
   "source": [
    "chathuman.train(Config.epochs, train_dataloader, valid_dataloader, True)\n",
    "# chathuman.save(f'models/{Config.model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3655b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chathuman.train_losses)\n",
    "plt.plot(chathuman.valid_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
