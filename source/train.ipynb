{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900ae5dc",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caeeb8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, time, datetime\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08bc23a",
   "metadata": {},
   "source": [
    "# 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d927c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_name = \"data/dialogue.csv\"\n",
    "    bos_token = '<s>'\n",
    "    eos_token = '</s>'\n",
    "    usr_token = '<usr>'\n",
    "    pad_token = '<pad>'\n",
    "    sys_token = '<sys>'\n",
    "    unk_token = '<unk>'\n",
    "    mask_token = '<mask>'\n",
    "    max_length = 2 ** 8\n",
    "    batch_size = 2 ** 3\n",
    "    epochs = 2 ** 2\n",
    "    pretrained_model_name = \"skt/kogpt2-base-v2\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 3e-5\n",
    "    model_name = 'model.pt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275ce1b",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086158a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(Config.data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e5adc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>&lt;usr&gt; 재훈재훈은자기가 좋아하는거 몰라고지식해내가 얘네보고드라마 쓴거아녀 &lt;sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192976</th>\n",
       "      <td>&lt;usr&gt; 오늘 광역버스를 타는데 아저씨가 정류장을 지나치려고 하는거야.&lt;sys&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176009</th>\n",
       "      <td>&lt;usr&gt; 오늘 바다 놀러 갔을 때 어땠어?&lt;sys&gt; 오랜만에 바다를 가니 좋았었어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161645</th>\n",
       "      <td>&lt;usr&gt; 안녕 친구요즘 매일 매일이 너무 바쁘다 ㅋㅋ&lt;sys&gt; 너 항상 바빴잖아 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113977</th>\n",
       "      <td>&lt;usr&gt; 전세보는거엿우? &lt;sys&gt; 웅웅월세는 돈이넘나많이나감ㅠㅠ &lt;usr&gt; 전세...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>&lt;usr&gt; 아 127 nonstop 노래 좋네내스타일이다 &lt;sys&gt; 그거약간세상을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76337</th>\n",
       "      <td>&lt;usr&gt; 난 어제 11시에 자서 9시반까지 쭉 자는 기염을 토해쩌 상쾌해그리고 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130734</th>\n",
       "      <td>&lt;usr&gt; 12월부터우리 1월말에 보겠네미리 준비하자 &lt;sys&gt; 짝짝좋아야어떤 옷을...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57081</th>\n",
       "      <td>&lt;usr&gt; 나지금 보험뭐할거있어서동탄잠깐갔는데초등학생들 어학원 &lt;sys&gt; ㅋㅋ &lt;u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22746</th>\n",
       "      <td>&lt;usr&gt; 으맞다선배님 &lt;sys&gt; 응응 &lt;usr&gt; 나한테 뭐화나신게아니라나땜에여자친...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194475 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             conversation\n",
       "536     <usr> 재훈재훈은자기가 좋아하는거 몰라고지식해내가 얘네보고드라마 쓴거아녀 <sy...\n",
       "192976  <usr> 오늘 광역버스를 타는데 아저씨가 정류장을 지나치려고 하는거야.<sys> ...\n",
       "176009  <usr> 오늘 바다 놀러 갔을 때 어땠어?<sys> 오랜만에 바다를 가니 좋았었어...\n",
       "161645  <usr> 안녕 친구요즘 매일 매일이 너무 바쁘다 ㅋㅋ<sys> 너 항상 바빴잖아 ...\n",
       "113977  <usr> 전세보는거엿우? <sys> 웅웅월세는 돈이넘나많이나감ㅠㅠ <usr> 전세...\n",
       "...                                                   ...\n",
       "7008    <usr> 아 127 nonstop 노래 좋네내스타일이다 <sys> 그거약간세상을 ...\n",
       "76337   <usr> 난 어제 11시에 자서 9시반까지 쭉 자는 기염을 토해쩌 상쾌해그리고 기...\n",
       "130734  <usr> 12월부터우리 1월말에 보겠네미리 준비하자 <sys> 짝짝좋아야어떤 옷을...\n",
       "57081   <usr> 나지금 보험뭐할거있어서동탄잠깐갔는데초등학생들 어학원 <sys> ㅋㅋ <u...\n",
       "22746   <usr> 으맞다선배님 <sys> 응응 <usr> 나한테 뭐화나신게아니라나땜에여자친...\n",
       "\n",
       "[194475 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(raw_data)\n",
    "data = raw_data.sample(N)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3b08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_size(train_X):\n",
    "    length = len(train_X)\n",
    "    return round(0.14 * (1 + length / 10 ** 4) ** (10 ** 4 / length) - 0.13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fb6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size=valid_size(data), shuffle=True)\n",
    "data_train.reset_index(inplace=True)\n",
    "data_valid.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c1efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189836</td>\n",
       "      <td>&lt;usr&gt; 아 왔을때 거기안갔다&lt;sys&gt; 어디&lt;usr&gt; 뼈해장국집&lt;sys&gt; 아 맞네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126293</td>\n",
       "      <td>&lt;usr&gt; 내일 길병원 가지 마엄니랑 아버지랑 간다니까. 정지혜 갈 필요 없어 &lt;s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113732</td>\n",
       "      <td>&lt;usr&gt; 언니터틀넥긴거 입을까짧은거 입을까 &lt;sys&gt; 긴거와 짧은거가어디가 짧은건...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72613</td>\n",
       "      <td>&lt;usr&gt; 김밥ㅋ사간당 &lt;sys&gt; ㅋㅋㅋㅋ한시간이나 남았노 &lt;usr&gt; 김밥 두줄사갈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27158</td>\n",
       "      <td>&lt;usr&gt; 나는 고구마나 유산균언제쯤 가지러갈수잇을까용 &lt;sys&gt; 언제되냐? &lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188635</th>\n",
       "      <td>96372</td>\n",
       "      <td>&lt;usr&gt; 근데나오늘책상 옮기고 파티션 만다는거회의실 세팅다잡아놔서오후엔 또 그거해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188636</th>\n",
       "      <td>26532</td>\n",
       "      <td>&lt;usr&gt; 박홍민야클래스돼? &lt;sys&gt; ㅋㅋ 안되는듯개거지같넹대기 중이랰ㅋㅋ &lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188637</th>\n",
       "      <td>120865</td>\n",
       "      <td>&lt;usr&gt; 드디어 폰바꾼다 &lt;sys&gt; 야호! &lt;usr&gt; 신났찌 &lt;sys&gt; xs로 바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188638</th>\n",
       "      <td>40066</td>\n",
       "      <td>&lt;usr&gt; 윤은진얌 약값도 보험비 청구 됑? &lt;sys&gt; 만원이상일 때만그런데 대부분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188639</th>\n",
       "      <td>107889</td>\n",
       "      <td>&lt;usr&gt; 최푸른 온통대전 유통기한지났을텐데 아직도 안 쓴 거 아니지? &lt;sys&gt; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                                       conversation\n",
       "0       189836  <usr> 아 왔을때 거기안갔다<sys> 어디<usr> 뼈해장국집<sys> 아 맞네...\n",
       "1       126293  <usr> 내일 길병원 가지 마엄니랑 아버지랑 간다니까. 정지혜 갈 필요 없어 <s...\n",
       "2       113732  <usr> 언니터틀넥긴거 입을까짧은거 입을까 <sys> 긴거와 짧은거가어디가 짧은건...\n",
       "3        72613  <usr> 김밥ㅋ사간당 <sys> ㅋㅋㅋㅋ한시간이나 남았노 <usr> 김밥 두줄사갈...\n",
       "4        27158  <usr> 나는 고구마나 유산균언제쯤 가지러갈수잇을까용 <sys> 언제되냐? <us...\n",
       "...        ...                                                ...\n",
       "188635   96372  <usr> 근데나오늘책상 옮기고 파티션 만다는거회의실 세팅다잡아놔서오후엔 또 그거해...\n",
       "188636   26532  <usr> 박홍민야클래스돼? <sys> ㅋㅋ 안되는듯개거지같넹대기 중이랰ㅋㅋ <us...\n",
       "188637  120865  <usr> 드디어 폰바꾼다 <sys> 야호! <usr> 신났찌 <sys> xs로 바...\n",
       "188638   40066  <usr> 윤은진얌 약값도 보험비 청구 됑? <sys> 만원이상일 때만그런데 대부분...\n",
       "188639  107889  <usr> 최푸른 온통대전 유통기한지났을텐데 아직도 안 쓴 거 아니지? <sys> ...\n",
       "\n",
       "[188640 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33cb3853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56193</td>\n",
       "      <td>&lt;usr&gt; 잘대구있니나는팀미팅좀해쓰ㅋㅋ앞으로머연구할지 &lt;sys&gt; 웅웅 ㅋㅋ미팅잘햇오...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185961</td>\n",
       "      <td>&lt;usr&gt; 너네회사도 동료들이랑 대화 많이해?&lt;sys&gt; 뭐 커피마시면서 수다떠는정도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35072</td>\n",
       "      <td>&lt;usr&gt; 목상태가 최악을 향해 달려가고있습니다 부릉부릉 &lt;sys&gt; 무슨일이일어나고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31082</td>\n",
       "      <td>&lt;usr&gt; 그외에 다른사람들하고는 잘지내구걍 저번에일땜에 한번 버럭한거밖에없는뎈ㅋ나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51354</td>\n",
       "      <td>&lt;usr&gt; 근데 문제가 생겼어포토존이 좀 짝네 &lt;sys&gt; 엥 그게 뭐얌 ?포토존도 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>132619</td>\n",
       "      <td>&lt;usr&gt; 나 월요일날 못만날수도 &lt;sys&gt; 왜?무슨일 있어? &lt;usr&gt; 아빠랑 찬...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5831</th>\n",
       "      <td>89745</td>\n",
       "      <td>&lt;usr&gt; 다른거 누르면 나올걸그래도 우선 티빙봐 &lt;sys&gt; 너 봤어? &lt;usr&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>130339</td>\n",
       "      <td>&lt;usr&gt; 나랑은직관언제가줘? &lt;sys&gt; 날잡아 &lt;usr&gt; 잡아줘 &lt;sys&gt; 언제갈...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>58577</td>\n",
       "      <td>&lt;usr&gt; 이번에 갑자기 5명늘었어무서워ㅠㅠ &lt;sys&gt; 하진짜 다단계 교회 이런게 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>88163</td>\n",
       "      <td>&lt;usr&gt; 아 선희아아내의 유혹 ㅠㅠ귀여워 &lt;sys&gt; 아내의유혹이재밌었대? &lt;usr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5835 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                       conversation\n",
       "0      56193  <usr> 잘대구있니나는팀미팅좀해쓰ㅋㅋ앞으로머연구할지 <sys> 웅웅 ㅋㅋ미팅잘햇오...\n",
       "1     185961  <usr> 너네회사도 동료들이랑 대화 많이해?<sys> 뭐 커피마시면서 수다떠는정도...\n",
       "2      35072  <usr> 목상태가 최악을 향해 달려가고있습니다 부릉부릉 <sys> 무슨일이일어나고...\n",
       "3      31082  <usr> 그외에 다른사람들하고는 잘지내구걍 저번에일땜에 한번 버럭한거밖에없는뎈ㅋ나...\n",
       "4      51354  <usr> 근데 문제가 생겼어포토존이 좀 짝네 <sys> 엥 그게 뭐얌 ?포토존도 ...\n",
       "...      ...                                                ...\n",
       "5830  132619  <usr> 나 월요일날 못만날수도 <sys> 왜?무슨일 있어? <usr> 아빠랑 찬...\n",
       "5831   89745  <usr> 다른거 누르면 나올걸그래도 우선 티빙봐 <sys> 너 봤어? <usr> ...\n",
       "5832  130339  <usr> 나랑은직관언제가줘? <sys> 날잡아 <usr> 잡아줘 <sys> 언제갈...\n",
       "5833   58577  <usr> 이번에 갑자기 5명늘었어무서워ㅠㅠ <sys> 하진짜 다단계 교회 이런게 ...\n",
       "5834   88163  <usr> 아 선희아아내의 유혹 ㅠㅠ귀여워 <sys> 아내의유혹이재밌었대? <usr...\n",
       "\n",
       "[5835 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79275e5",
   "metadata": {},
   "source": [
    "# 3. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ec2851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Config.pretrained_model_name,\n",
    "            bos_token=Config.bos_token, eos_token=Config.eos_token,\n",
    "            unk_token=Config.unk_token, pad_token=Config.pad_token,\n",
    "            mask_token=Config.mask_token, model_max_length=Config.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34bd7629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <usr> <pad> <sys> <unk> <mask> <d> </d> <unused0> "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tokenizer.convert_ids_to_tokens(i), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0a7b6",
   "metadata": {},
   "source": [
    "# 4. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7f0fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, Config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.pad_token = Config.pad_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.max_length = Config.max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data['conversation'][idx]\n",
    "        # input_id\n",
    "        input_id = self.tokenizer.encode(self.bos_token + sentence + self.eos_token)\n",
    "        # token_type_id\n",
    "        token_type = []\n",
    "        loop = True\n",
    "        for token_id in input_id:\n",
    "            token = self.tokenizer.convert_ids_to_tokens(token_id)\n",
    "            \n",
    "            if token == self.usr_token: loop=True\n",
    "            elif token == self.sys_token: loop=False\n",
    "                \n",
    "            if loop:\n",
    "                token_type.append(self.usr_token)\n",
    "            else:\n",
    "                token_type.append(self.sys_token)\n",
    "        token_type_id = self.tokenizer.convert_tokens_to_ids(token_type)\n",
    "        # label\n",
    "#         start_idx = len(input_id) - \\\n",
    "#             list(reversed(input_id)).index(self.tokenizer.convert_tokens_to_ids(self.sys_token))\n",
    "#         label = [-100] * start_idx + input_id[start_idx: ]\n",
    "        # padding\n",
    "        input_id, token_type_id, label = self.make_padding(input_id, token_type_id, input_id)\n",
    "        \n",
    "        return input_id, token_type_id, input_id\n",
    "\n",
    "    def make_padding(self, input_id, token_type_id, label):\n",
    "        left_length = self.max_length - len(input_id)\n",
    "        input_id += [self.tokenizer.pad_token_id] * left_length\n",
    "        token_type_id += [self.tokenizer.pad_token_id] * left_length\n",
    "#         label += [-100] * left_length\n",
    "        \n",
    "        return input_id, token_type_id, input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978e6a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(data_train, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15bceeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 9050, 12583, 8137, 7312, 41732, 7967, 6834, 7182, 4, 13400, 2, 13219, 8711, 46812, 8270, 4, 9050, 9622, 7098, 12829, 7060, 9028, 9436, 24848, 9098, 15010, 2, 30401, 13134, 9114, 23775, 9220, 7789, 27450, 31369, 9117, 7703, 7788, 9078, 8702, 4, 25942, 9034, 8137, 11242, 31522, 2, 31416, 30401, 8024, 9034, 8137, 49542, 8263, 4, 13219, 8711, 46812, 9784, 8133, 27006, 8159, 739, 605, 605, 2, 41732, 11355, 8270, 9383, 41787, 28478, 30613, 8711, 15010, 15354, 8137, 9183, 6824, 7098, 4, 16518, 9208, 18128, 17133, 6824, 2, 41732, 11355, 8270, 9131, 28005, 7235, 9183, 8711, 8240, 9705, 7609, 8285, 8152, 4, 28005, 7692, 7071, 7235, 9183, 15084, 7055, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[0, 2, 9050, 12583, 8137, 7312, 41732, 7967, 6834, 7182, 4, 13400, 2, 13219, 8711, 46812, 8270, 4, 9050, 9622, 7098, 12829, 7060, 9028, 9436, 24848, 9098, 15010, 2, 30401, 13134, 9114, 23775, 9220, 7789, 27450, 31369, 9117, 7703, 7788, 9078, 8702, 4, 25942, 9034, 8137, 11242, 31522, 2, 31416, 30401, 8024, 9034, 8137, 49542, 8263, 4, 13219, 8711, 46812, 9784, 8133, 27006, 8159, 739, 605, 605, 2, 41732, 11355, 8270, 9383, 41787, 28478, 30613, 8711, 15010, 15354, 8137, 9183, 6824, 7098, 4, 16518, 9208, 18128, 17133, 6824, 2, 41732, 11355, 8270, 9131, 28005, 7235, 9183, 8711, 8240, 9705, 7609, 8285, 8152, 4, 28005, 7692, 7071, 7235, 9183, 15084, 7055, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = train_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cdcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [items[0] for items in batch]\n",
    "    token_type_ids = [items[1] for items in batch]\n",
    "    labels = [items[2] for items in batch]\n",
    "    \n",
    "    return torch.LongTensor(input_ids), torch.LongTensor(token_type_ids), \\\n",
    "            torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43cd52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                              shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ba88d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = CustomDataset(data_valid, tokenizer, Config)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                            shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d2e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 9443, 29161, 8155, 7172, 10972, 8612, 7584, 8614, 8217, 8711, 7949, 605, 605, 7981, 9021, 7512, 9830, 8705, 8263, 739, 4, 11786, 8101, 739, 605, 605, 7584, 8614, 8163, 8717, 8052, 406, 739, 2, 11018, 9685, 7253, 6866, 7490, 7098, 216, 739, 4, 10152, 406, 739, 216, 27752, 8614, 10132, 9779, 739, 376, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[0, 2, 9443, 29161, 8155, 7172, 10972, 8612, 7584, 8614, 8217, 8711, 7949, 605, 605, 7981, 9021, 7512, 9830, 8705, 8263, 739, 4, 11786, 8101, 739, 605, 605, 7584, 8614, 8163, 8717, 8052, 406, 739, 2, 11018, 9685, 7253, 6866, 7490, 7098, 216, 739, 4, 10152, 406, 739, 216, 27752, 8614, 10132, 9779, 739, 376, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = valid_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9b86d",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c195361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(Config.pretrained_model_name).to(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d98650",
   "metadata": {},
   "source": [
    "# 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3b4e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, model, tokenizer, Config):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=Config.learning_rate)\n",
    "#         self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.9)\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.device = Config.device\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "\n",
    "    def train(self, epochs, train_dataloader, valid_dataloader=None, save=False):\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch: {epoch + 1} / {epochs}\")\n",
    "            self.model.train()\n",
    "            losses = []\n",
    "            start_time = time.time()\n",
    "\n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch        \n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                train_loss = np.mean(losses)\n",
    "                print(self.status(i + 1, len(train_dataloader), time.time() - start_time,\n",
    "                                  train_loss), end='\\r')\n",
    "                \n",
    "#             self.scheduler.step()\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            if valid_dataloader:\n",
    "                valid_loss = self.validation(valid_dataloader)\n",
    "                print(self.status(i + 1, len(train_dataloader), time.time() - start_time,\n",
    "                                train_loss) + f\" #valid_loss: {valid_loss:.6f}\\n\", end='\\r')\n",
    "                self.valid_losses.append(valid_loss)\n",
    "            \n",
    "            if save:\n",
    "                time_zone = datetime.timezone(datetime.timedelta(hours=9))\n",
    "                now = datetime.datetime.now(time_zone)\n",
    "                PATH = now.strftime(f'models/%m%d_%H%M_ep{epoch + 1}.pt')\n",
    "                torch.save(self.model.state_dict(), PATH)\n",
    "\n",
    "    def validation(self, valid_dataloader):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(valid_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = \\\n",
    "                    input_ids.to(self.device), token_type_ids.to(self.device), labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                losses.append(loss.item())\n",
    "            \n",
    "            valid_loss = np.mean(losses)\n",
    "        \n",
    "        return valid_loss\n",
    "    \n",
    "    def status(self, step, steps, past_time, train_loss):\n",
    "        return f\"#step: {step} / {steps} #past: {int(past_time)}s #left: {int(steps / step * past_time - past_time)}s #train_loss: {train_loss:.6f}\"\n",
    "\n",
    "    def save(self, PATH=None):\n",
    "        if not PATH:\n",
    "            time_zone = datetime.timezone(datetime.timedelta(hours=9))\n",
    "            now = datetime.datetime.now(time_zone)\n",
    "            PATH = now.strftime(f'models/%m%d_%H%M_ep{epochs}.pt')\n",
    "            \n",
    "        torch.save(self.model.state_dict(), PATH)\n",
    "        print(\"model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a658c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chathuman = Train(model, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chathuman.train(Config.epochs, train_dataloader, valid_dataloader, True)\n",
    "# chathuman.save(f'models/{Config.model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3681bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chathuman.train_losses)\n",
    "plt.plot(chathuman.valid_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444498d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50a8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fb4cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5078ed8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919981e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a4f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c107eef297635ad14658a1d112b6ceb6b3114645fe0e4cbc59ce20122790fa9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
