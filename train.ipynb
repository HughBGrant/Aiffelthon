{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049f5806",
   "metadata": {},
   "source": [
    "# 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba69fc63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, time\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from tqdm import tqdm\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container {width:100% !important;}</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f35fc3",
   "metadata": {},
   "source": [
    "# 1. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648b6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    bos_token = '<s>'\n",
    "    eos_token = '</s>'\n",
    "    usr_token = '<usr>'\n",
    "    pad_token = '<pad>'\n",
    "    sys_token = '<sys>'\n",
    "    unk_token = '<unk>'\n",
    "    mask_token = '<mask>'\n",
    "    max_length = 256\n",
    "    max_turns = 8\n",
    "    epochs = 2\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    learning_rate = 1e-4\n",
    "    model_name = \"skt/kogpt2-base-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5170fe",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36bbff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/kakao_len256.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8d08d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43111</th>\n",
       "      <td>&lt;usr&gt; 헬스장 갔다 사우나 하고 나오니 기분 좋네요&lt;sys&gt; 전 오늘 스카이다이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48021</th>\n",
       "      <td>&lt;usr&gt; 군대에서 한 달에 한번 행군을 해&lt;sys&gt; 행군? 그게 뭐야? 걷는거?&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56117</th>\n",
       "      <td>&lt;usr&gt; 넌 흥부와 놀부 중에 누가 좋니?&lt;sys&gt; 당연히 놀부&lt;usr&gt; 특이하네...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20758</th>\n",
       "      <td>&lt;usr&gt; 너 배우 마동석 좋아해?&lt;sys&gt; 응 마동석 너무 좋아하지&lt;usr&gt; 나 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50760</th>\n",
       "      <td>&lt;usr&gt; 반려동물 시장이 갈수록 커져&lt;sys&gt; 응. 물건들도 다양해졌어&lt;usr&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48953</th>\n",
       "      <td>&lt;usr&gt; 변요한이 영화공약했었잖아&lt;sys&gt; 관객 얼마 이상되면 춤 추겠다던거?&lt;u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12048</th>\n",
       "      <td>&lt;usr&gt; 나 요즘 시골 내려가서 살고싶어&lt;sys&gt; 갑자기 왠 시골이야?&lt;usr&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51000</th>\n",
       "      <td>&lt;usr&gt; 할인할 때 왕창 사놓는 물건 있어?&lt;sys&gt; 고기 세일하면 사놓는 편이야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40585</th>\n",
       "      <td>&lt;usr&gt; 얘들아 나 고민 있어.&lt;sys&gt; 무슨 일이야?&lt;usr&gt; 뭔데? 말해봐 봐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45280</th>\n",
       "      <td>&lt;usr&gt; 내 사촌 이번에 아이폰 장만했대 ㅋㅋ&lt;sys&gt; 아이폰 새로 나온 거 샀대...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            conversation\n",
       "43111  <usr> 헬스장 갔다 사우나 하고 나오니 기분 좋네요<sys> 전 오늘 스카이다이...\n",
       "48021  <usr> 군대에서 한 달에 한번 행군을 해<sys> 행군? 그게 뭐야? 걷는거?<...\n",
       "56117  <usr> 넌 흥부와 놀부 중에 누가 좋니?<sys> 당연히 놀부<usr> 특이하네...\n",
       "20758  <usr> 너 배우 마동석 좋아해?<sys> 응 마동석 너무 좋아하지<usr> 나 ...\n",
       "50760  <usr> 반려동물 시장이 갈수록 커져<sys> 응. 물건들도 다양해졌어<usr> ...\n",
       "...                                                  ...\n",
       "48953  <usr> 변요한이 영화공약했었잖아<sys> 관객 얼마 이상되면 춤 추겠다던거?<u...\n",
       "12048  <usr> 나 요즘 시골 내려가서 살고싶어<sys> 갑자기 왠 시골이야?<usr> ...\n",
       "51000  <usr> 할인할 때 왕창 사놓는 물건 있어?<sys> 고기 세일하면 사놓는 편이야...\n",
       "40585  <usr> 얘들아 나 고민 있어.<sys> 무슨 일이야?<usr> 뭔데? 말해봐 봐...\n",
       "45280  <usr> 내 사촌 이번에 아이폰 장만했대 ㅋㅋ<sys> 아이폰 새로 나온 거 샀대...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000# len(raw_data)\n",
    "data = raw_data.sample(N)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327c96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_size(train_X):\n",
    "    length = len(train_X)\n",
    "    return round(0.14 * (1 + length / 10 ** 4) ** (10 ** 4 / length) - 0.13, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c1e1ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size=valid_size(data), shuffle=True)\n",
    "data_train.reset_index(inplace=True)\n",
    "data_valid.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bea3b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47510</td>\n",
       "      <td>&lt;usr&gt; 라라랜드 같은 영화 보고싶다&lt;sys&gt; 라라랜드 완전 명작이잖아 하하&lt;us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36834</td>\n",
       "      <td>&lt;usr&gt; 언니 요즘 뭐 보는 거 있어?&lt;sys&gt; 스우파랑 오징어 게임 봤어 그리고...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28561</td>\n",
       "      <td>&lt;usr&gt; 오늘 무신사에서 산 옷 배송 온다&lt;sys&gt; 거기 배송 느리다던데 진짜야?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20282</td>\n",
       "      <td>&lt;usr&gt; 하하 부대 위치는 어디였어?&lt;sys&gt; 나 부대 위치는 송탄이라고 있는데 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33848</td>\n",
       "      <td>&lt;usr&gt; 오빠는 배그 집에서 안해?&lt;sys&gt; 배그는 하면 눈이 너무 아프더라..&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>12820</td>\n",
       "      <td>&lt;usr&gt; 결혼정보회사 가입 어떻게 하지?&lt;sys&gt; 이런 저런 서류들이 필요할 거야...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>57941</td>\n",
       "      <td>&lt;usr&gt; 언니 예전에 애들 친구들이랑 생일파티 했다 아니예요?&lt;sys&gt; 그래 그 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>36073</td>\n",
       "      <td>&lt;usr&gt; 전기료가 오른다네유..물가 무엇..&lt;sys&gt; 그러게요.. 이래서 전기차 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>36920</td>\n",
       "      <td>&lt;usr&gt; 니 형있다 했제? ㅋㅋ니네 형은 결혼하셨나? ㅋㅋ&lt;sys&gt; 아니요 아직 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>5734</td>\n",
       "      <td>&lt;usr&gt; 전주에는 왜 지하철이 없을까?&lt;sys&gt; 인구가 적으니까 지하철 하기에는 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                       conversation\n",
       "0    47510  <usr> 라라랜드 같은 영화 보고싶다<sys> 라라랜드 완전 명작이잖아 하하<us...\n",
       "1    36834  <usr> 언니 요즘 뭐 보는 거 있어?<sys> 스우파랑 오징어 게임 봤어 그리고...\n",
       "2    28561  <usr> 오늘 무신사에서 산 옷 배송 온다<sys> 거기 배송 느리다던데 진짜야?...\n",
       "3    20282  <usr> 하하 부대 위치는 어디였어?<sys> 나 부대 위치는 송탄이라고 있는데 ...\n",
       "4    33848  <usr> 오빠는 배그 집에서 안해?<sys> 배그는 하면 눈이 너무 아프더라..<...\n",
       "..     ...                                                ...\n",
       "765  12820  <usr> 결혼정보회사 가입 어떻게 하지?<sys> 이런 저런 서류들이 필요할 거야...\n",
       "766  57941  <usr> 언니 예전에 애들 친구들이랑 생일파티 했다 아니예요?<sys> 그래 그 ...\n",
       "767  36073  <usr> 전기료가 오른다네유..물가 무엇..<sys> 그러게요.. 이래서 전기차 ...\n",
       "768  36920  <usr> 니 형있다 했제? ㅋㅋ니네 형은 결혼하셨나? ㅋㅋ<sys> 아니요 아직 ...\n",
       "769   5734  <usr> 전주에는 왜 지하철이 없을까?<sys> 인구가 적으니까 지하철 하기에는 ...\n",
       "\n",
       "[770 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99645660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>conversation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29035</td>\n",
       "      <td>&lt;usr&gt; 놀럭자놀러가자&lt;sys&gt; 좋아좋아&lt;usr&gt; 어디든..&lt;sys&gt; 담달에 추석...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10207</td>\n",
       "      <td>&lt;usr&gt; 복도식아파트살면 복도가 자기껀줄 착각하나?&lt;sys&gt; 으..뭔일있는거야 왜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>451</td>\n",
       "      <td>&lt;usr&gt; 오징어게임 인기가 오래간다&lt;sys&gt; 그러게 식을 줄을 모르네&lt;usr&gt; 뉴...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54976</td>\n",
       "      <td>&lt;usr&gt; 야 나 어제 입원 했다&lt;sys&gt; 갑자기 무슨 일이야?&lt;usr&gt; 어제 일 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46453</td>\n",
       "      <td>&lt;usr&gt; 글램핑은 대전 내인가요?&lt;sys&gt; 아뇨 논산이래요&lt;usr&gt; 거리는 얼마나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>17825</td>\n",
       "      <td>&lt;usr&gt; 신랑이 이사온곳에 미용실을 못뚫어서 ㅋ&lt;sys&gt; 썬크림 바르고 가렴 ㅋㅋ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>37154</td>\n",
       "      <td>&lt;usr&gt; 밖에 나왔는데 제법 쌀쌀해&lt;sys&gt; 산에 갔을 땐 더웠는데 내려오니 추워...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>55356</td>\n",
       "      <td>&lt;usr&gt; 굿플레이스라고 들어봤어?&lt;sys&gt; 아니 그것도 처음 들어봤어&lt;usr&gt; 이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>52592</td>\n",
       "      <td>&lt;usr&gt; 베이징에선 벌써 첫눈이 내린 모양이구만&lt;sys&gt; 벌써? 아직 12월도 안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>34189</td>\n",
       "      <td>&lt;usr&gt; 이번에 우리 누나 결혼한다는데 내가 왜 떨리지 ㅋㅋ&lt;sys&gt; 오 이번에 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                       conversation\n",
       "0    29035  <usr> 놀럭자놀러가자<sys> 좋아좋아<usr> 어디든..<sys> 담달에 추석...\n",
       "1    10207  <usr> 복도식아파트살면 복도가 자기껀줄 착각하나?<sys> 으..뭔일있는거야 왜...\n",
       "2      451  <usr> 오징어게임 인기가 오래간다<sys> 그러게 식을 줄을 모르네<usr> 뉴...\n",
       "3    54976  <usr> 야 나 어제 입원 했다<sys> 갑자기 무슨 일이야?<usr> 어제 일 ...\n",
       "4    46453  <usr> 글램핑은 대전 내인가요?<sys> 아뇨 논산이래요<usr> 거리는 얼마나...\n",
       "..     ...                                                ...\n",
       "225  17825  <usr> 신랑이 이사온곳에 미용실을 못뚫어서 ㅋ<sys> 썬크림 바르고 가렴 ㅋㅋ...\n",
       "226  37154  <usr> 밖에 나왔는데 제법 쌀쌀해<sys> 산에 갔을 땐 더웠는데 내려오니 추워...\n",
       "227  55356  <usr> 굿플레이스라고 들어봤어?<sys> 아니 그것도 처음 들어봤어<usr> 이...\n",
       "228  52592  <usr> 베이징에선 벌써 첫눈이 내린 모양이구만<sys> 벌써? 아직 12월도 안...\n",
       "229  34189  <usr> 이번에 우리 누나 결혼한다는데 내가 왜 떨리지 ㅋㅋ<sys> 오 이번에 ...\n",
       "\n",
       "[230 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6293e",
   "metadata": {},
   "source": [
    "# 3. Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a23a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Config.model_name,\n",
    "            bos_token=Config.bos_token, eos_token=Config.eos_token,\n",
    "            unk_token=Config.unk_token, pad_token=Config.pad_token,\n",
    "            mask_token=Config.mask_token, model_max_length=Config.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb070a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <usr> <pad> <sys> <unk> <mask> <d> </d> <unused0> "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(tokenizer.convert_ids_to_tokens(i), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa551aa1",
   "metadata": {},
   "source": [
    "# 4. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a57e53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, Config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.pad_token = Config.pad_token\n",
    "        self.sys_token = Config.sys_token\n",
    "\n",
    "        self.max_length = Config.max_length\n",
    "        self.max_turns = Config.max_turns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data['conversation'][idx]\n",
    "        # input_id\n",
    "        input_id = self.tokenizer.encode(self.bos_token + sentence + self.eos_token)\n",
    "        # token_type_id\n",
    "        token_type = []\n",
    "        loop = True\n",
    "        for token_id in input_id:\n",
    "            token = self.tokenizer.convert_ids_to_tokens(token_id)\n",
    "            \n",
    "            if token == self.usr_token: loop=True\n",
    "            elif token == self.sys_token: loop=False\n",
    "                \n",
    "            if loop:\n",
    "                token_type.append(self.usr_token)\n",
    "            else:\n",
    "                token_type.append(self.sys_token)\n",
    "        token_type_id = self.tokenizer.convert_tokens_to_ids(token_type)\n",
    "        # label\n",
    "        start_idx = len(input_id) - list(reversed(input_id)).index(self.tokenizer.convert_tokens_to_ids(self.sys_token))\n",
    "        label = [-100] * start_idx + input_id[start_idx: ]\n",
    "        # padding\n",
    "        input_id, token_type_id, label = self.make_padding(input_id, token_type_id, label)\n",
    "        \n",
    "        return input_id, token_type_id, label\n",
    "\n",
    "    def make_padding(self, input_id, token_type_id, label):\n",
    "        left_length = self.max_length - len(input_id)\n",
    "        input_id += [self.tokenizer.pad_token_id] * left_length\n",
    "        token_type_id += [self.tokenizer.pad_token_id] * left_length\n",
    "        label += [-100] * left_length\n",
    "        \n",
    "        return input_id, token_type_id, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61d53a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDataset(data_train, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06ab6a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 9755, 7372, 9936, 9239, 10584, 10056, 7898, 7182, 4, 9755, 7372, 9936, 10253, 9170, 25138, 8162, 7965, 9078, 8702, 2, 15247, 12102, 9018, 6857, 10584, 17692, 9350, 7662, 7182, 739, 216, 4, 20713, 12858, 30616, 9843, 13454, 9078, 8702, 2, 9198, 23775, 13444, 7991, 376, 13348, 9774, 7623, 8137, 739, 7662, 15433, 10125, 7372, 4, 9769, 9755, 7372, 9936, 10288, 13394, 6824, 12371, 12011, 2, 9050, 9022, 6853, 9034, 6890, 19778, 9867, 9564, 9625, 16693, 4, 15247, 9036, 6890, 8704, 6890, 9054, 12011, 10104, 6919, 739, 216, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 15247, 9036, 6890, 8704, 6890, 9054, 12011, 10104, 6919, 739, 216, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = train_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e950337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [items[0] for items in batch]\n",
    "    token_type_ids = [items[1] for items in batch]\n",
    "    labels = [items[2] for items in batch]\n",
    "    \n",
    "    return torch.LongTensor(input_ids), torch.LongTensor(token_type_ids), \\\n",
    "            torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e25e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                              shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eaefabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = CustomDataset(data_valid, tokenizer, Config)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=Config.batch_size, num_workers=2,\n",
    "                            shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f6768aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_id\n",
      "[0, 2, 10624, 7398, 8159, 7122, 27006, 8159, 4, 12011, 8223, 7965, 2, 13400, 7283, 9705, 4, 9467, 48988, 9220, 7789, 8033, 8791, 7312, 15359, 25594, 9700, 33778, 9330, 19816, 9546, 47804, 7965, 7172, 7532, 11528, 7235, 10586, 7220, 2, 11786, 8101, 16256, 7058, 13400, 7283, 9054, 9677, 6960, 8704, 7220, 28737, 7380, 20130, 9054, 12011, 6949, 7220, 11528, 8135, 9183, 7253, 6853, 6838, 36598, 6953, 12371, 9286, 8265, 8159, 23982, 216, 4, 15247, 9018, 18554, 9286, 8265, 8159, 22683, 7536, 9168, 15182, 7788, 12079, 16179, 6958, 20164, 14520, 9019, 6960, 8704, 7220, 8397, 7789, 7312, 9168, 10307, 7478, 6962, 16098, 9685, 8263, 8163, 9511, 12858, 42351, 10307, 7481, 14520, 9019, 8018, 2, 9320, 9018, 18554, 11528, 8146, 17733, 8519, 18048, 9022, 6853, 15546, 9286, 8265, 8159, 9564, 12964, 7788, 24237, 21716, 7898, 8135, 7220, 9350, 6824, 6872, 8006, 216, 4, 16518, 11528, 7492, 6889, 9306, 6899, 20130, 9955, 8006, 8335, 8694, 9546, 6899, 8135, 9146, 8161, 8710, 9078, 8702, 2, 16256, 22979, 9779, 18848, 7652, 8159, 739, 216, 15063, 10624, 28142, 13375, 8263, 4, 739, 11786, 8092, 9198, 8168, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "token_type_id\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "label\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 739, 11786, 8092, 9198, 8168, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "input_id, token_type_id, label = valid_set[0]\n",
    "print(\"input_id\", input_id, sep='\\n')\n",
    "print(\"token_type_id\", token_type_id, sep='\\n')\n",
    "print(\"label\", label, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b012bf38",
   "metadata": {},
   "source": [
    "# 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb09f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(Config.model_name).to(Config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ba875",
   "metadata": {},
   "source": [
    "# 6. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e75eb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, model, tokenizer, Config):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=Config.learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.9)\n",
    "        self.bos_token = Config.bos_token\n",
    "        self.eos_token = Config.eos_token\n",
    "        self.usr_token = Config.usr_token\n",
    "        self.sys_token = Config.sys_token\n",
    "        self.max_length = Config.max_length\n",
    "        self.max_turns = Config.max_turns\n",
    "        self.device = Config.device\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.history = []\n",
    "\n",
    "    def train(self, epochs, train_dataloader, validation_dataloader=None, save=None):\n",
    "        self.model.train()\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"\\n Epoch {epoch+1}/{epochs}\", sep=\"\\n\")\n",
    "            batch_loss = []\n",
    "            start_time = time.time()\n",
    "\n",
    "            for i, batch in enumerate(train_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch        \n",
    "                input_ids, token_type_ids, labels = input_ids.to(self.device), token_type_ids.to(self.device), \\\n",
    "                                                    labels.to(self.device)\n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                batch_loss.append(loss.item())\n",
    "                \n",
    "                print(self.status(i+1, len(train_dataloader), time.time()-start_time, np.mean(batch_loss)), end='\\r')\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            self.losses.append(np.mean(batch_loss))\n",
    "            \n",
    "            if validation_dataloader:\n",
    "                val_loss = self.validation(validation_dataloader)\n",
    "                print(self.status(i+1, len(train_dataloader), time.time()-start_time, np.mean(batch_loss)) + \\\n",
    "                      \" | val_loss : %.6f\"%(val_loss), end='\\r')\n",
    "                self.val_losses.append(val_loss)\n",
    "            \n",
    "            if save:\n",
    "                time_zone = datetime.timezone(datetime.timedelta(hours=9))\n",
    "                now = datetime.datetime.now(time_zone)\n",
    "                PATH = now.strftime(f'./check_point/%Y-%m-%d-%Hh-%Mm_epoch_{epoch+1}.pth')\n",
    "                torch.save(self.model.state_dict(), PATH)\n",
    "\n",
    "    def validation(self, validation_dataloader):\n",
    "        self.model.eval()\n",
    "        batch_loss = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(validation_dataloader):\n",
    "                input_ids, token_type_ids, labels = batch\n",
    "                input_ids, token_type_ids, labels = input_ids.to(self.device), token_type_ids.to(self.device),\\\n",
    "                                                    labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(\n",
    "                    input_ids = input_ids,\n",
    "                    token_type_ids = token_type_ids,\n",
    "                    labels = labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                batch_loss.append(loss.item())\n",
    "            \n",
    "            valid_loss = np.mean(batch_loss)\n",
    "        \n",
    "        return valid_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def status(step, step_len, time, loss):\n",
    "        return f\"step: {step} / {step_len} - {int(time)} s | loss: {loss:.6f} | {step/time:.2f} it/s\"\n",
    "\n",
    "    def save(self, PATH=None):\n",
    "        if not PATH:\n",
    "            now = datetime.datetime.now()\n",
    "            now_date = now.strftime('%m%d_%H%M')\n",
    "            PATH = 'models/' + str(now_date) + '_model.pt'\n",
    "        torch.save(self.model.state_dict(), PATH)\n",
    "        print(\"model saved.\")\n",
    "\n",
    "    def load(self, PATH):\n",
    "        self.model.load_state_dict(torch.load(PATH))\n",
    "        print(\"model loaded.\")\n",
    "        \n",
    "    def chat(self):\n",
    "        while True:\n",
    "            usr_sent = input(\"user > \")\n",
    "\n",
    "            if usr_sent == \"끝\": break\n",
    "            if usr_sent == \"초기화\":\n",
    "                history = []\n",
    "                continue\n",
    "            if len(self.history) == self.max_turns * 2:\n",
    "                self.history = self.history[2: ]\n",
    "                self.history[0] = self.bos_token + self.history[0]\n",
    "            \n",
    "            usr_sent_pull = self.usr_token + usr_sent + self.sys_token\n",
    "            if len(self.history) == 0:\n",
    "                usr_sent_pull = self.bos_token + usr_sent_pull\n",
    "\n",
    "            self.history.append(usr_sent_pull)\n",
    "\n",
    "            input_id = self.tokenizer.encode(''.join(self.history), return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output_id = model.generate(\n",
    "                            input_id,\n",
    "                            max_length=1000,\n",
    "                            do_samples=True,\n",
    "                            temperature=0.8,\n",
    "                            top_k=100,\n",
    "                            top_p=0.95,\n",
    "                            max_new_tokens=30,\n",
    "                            eos_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "                \n",
    "            output = self.tokenizer.decode(output_id[0])\n",
    "            sys_sent = output.split('<sys>')[-1][: -4]\n",
    "            print(f'Chatbot > {sys_sent}')\n",
    "            \n",
    "            self.history.append(sys_sent)\n",
    "            print(len(self.history)//2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59ca7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "chathuman = Train(model, tokenizer, Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a725b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/2\n",
      "step: 36 / 193 - 11 s | loss: 5.322366 | 3.19 it/s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_422/3555201759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchathuman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_422/2601569686.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_dataloader, validation_dataloader, save)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             F.adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chathuman.train(Config.epochs, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3123ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved.\n"
     ]
    }
   ],
   "source": [
    "PATH = 'models/model.pt'\n",
    "chathuman.save(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97924d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(chathuman.losses)\n",
    "plt.plot(chathuman.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f71e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
